from transformers import MarianMTModel, MarianTokenizer
from config import settings
from utils.logger import logger
from typing import Optional


class Translator:
    """æ—¥è‹±ç¿»è¨³ã‚’è¡Œã†ã‚¯ãƒ©ã‚¹ï¼ˆHelsinki-NLP/opus-mt-ja-enï¼‰"""

    def __init__(self):
        self.model: Optional[MarianMTModel] = None
        self.tokenizer: Optional[MarianTokenizer] = None
        self.model_name = settings.TRANSLATION_MODEL
        self.max_length = settings.MAX_TRANSLATION_LENGTH
        self.device = settings.TRANSLATION_DEVICE

    def _load_model(self):
        """ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ãƒ­ãƒ¼ãƒ‰ï¼ˆé…å»¶ãƒ­ãƒ¼ãƒ‰ï¼‰"""
        if self.model is not None and self.tokenizer is not None:
            return

        try:
            logger.info(f"ğŸ”„ ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ä¸­: {self.model_name}")
            self.tokenizer = MarianTokenizer.from_pretrained(self.model_name)
            self.model = MarianMTModel.from_pretrained(self.model_name)
            self.model.to(self.device)
            self.model.eval()
            logger.info(f"âœ… ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰å®Œäº†")
        except Exception as e:
            logger.exception(f"âŒ ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {e}")
            raise RuntimeError(f"ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def translate_text(self, text: str) -> str:
        """
        æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆã‚’è‹±èªã«ç¿»è¨³

        Args:
            text: ç¿»è¨³å¯¾è±¡ã®æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            ç¿»è¨³ã•ã‚ŒãŸè‹±èªãƒ†ã‚­ã‚¹ãƒˆ
        """
        if not text or not text.strip():
            logger.warning("âš ï¸ ç©ºã®ãƒ†ã‚­ã‚¹ãƒˆãŒæ¸¡ã•ã‚Œã¾ã—ãŸ")
            return ""

        try:
            # ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆåˆå›ã®ã¿ï¼‰
            self._load_model()

            # é•·æ–‡ã®å ´åˆã¯åˆ†å‰²å‡¦ç†
            if len(text) > self.max_length:
                logger.info(
                    f"ğŸ“ é•·æ–‡ã‚’åˆ†å‰²å‡¦ç†ã—ã¾ã™ï¼ˆ{len(text)}æ–‡å­— > {self.max_length}æ–‡å­—ï¼‰"
                )
                return self._translate_long_text(text)

            # é€šå¸¸ã®ç¿»è¨³å‡¦ç†
            logger.info(f"ğŸ”„ ç¿»è¨³é–‹å§‹: {text[:50]}...")
            translated = self._translate_chunk(text)
            logger.info(f"âœ… ç¿»è¨³å®Œäº†: {translated[:50]}...")
            return translated

        except Exception as e:
            logger.exception(f"âŒ ç¿»è¨³ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
            raise RuntimeError(f"ç¿»è¨³å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

    def _translate_chunk(self, text: str) -> str:
        """
        å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã®ç¿»è¨³å‡¦ç†

        Args:
            text: ç¿»è¨³å¯¾è±¡ãƒ†ã‚­ã‚¹ãƒˆï¼ˆmax_lengthä»¥å†…ï¼‰

        Returns:
            ç¿»è¨³çµæœ
        """
        # ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚º
        inputs = self.tokenizer(
            text, return_tensors="pt", padding=True, truncation=True, max_length=512
        ).to(self.device)

        # ç¿»è¨³ç”Ÿæˆ
        translated_tokens = self.model.generate(**inputs)

        # ãƒ‡ã‚³ãƒ¼ãƒ‰
        translated_text = self.tokenizer.decode(
            translated_tokens[0], skip_special_tokens=True
        )

        return translated_text

    def _translate_long_text(self, text: str) -> str:
        """
        é•·æ–‡ã‚’åˆ†å‰²ã—ã¦ç¿»è¨³

        Args:
            text: é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆ

        Returns:
            åˆ†å‰²ç¿»è¨³ã•ã‚ŒãŸçµæœã‚’çµåˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆ
        """
        # å¥ç‚¹ã§åˆ†å‰²
        sentences = text.split("ã€‚")
        chunks = []
        current_chunk = ""

        for sentence in sentences:
            if not sentence.strip():
                continue

            # ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’è¶…ãˆã‚‹å ´åˆã¯æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã¸
            if len(current_chunk) + len(sentence) + 1 > self.max_length:
                if current_chunk:
                    chunks.append(current_chunk)
                current_chunk = sentence + "ã€‚"
            else:
                current_chunk += sentence + "ã€‚"

        # æ®‹ã‚Šã‚’è¿½åŠ 
        if current_chunk:
            chunks.append(current_chunk)

        logger.info(f"ğŸ“¦ {len(chunks)}å€‹ã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²ã—ã¾ã—ãŸ")

        # å„ãƒãƒ£ãƒ³ã‚¯ã‚’ç¿»è¨³
        translated_chunks = []
        for i, chunk in enumerate(chunks):
            logger.info(f"ğŸ”„ ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(chunks)} ã‚’ç¿»è¨³ä¸­...")
            translated = self._translate_chunk(chunk)
            translated_chunks.append(translated)

        # çµåˆã—ã¦è¿”ã™
        result = " ".join(translated_chunks)
        logger.info(f"âœ… å…¨ãƒãƒ£ãƒ³ã‚¯ã®ç¿»è¨³å®Œäº†")
        return result


# ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
_translator_instance: Optional[Translator] = None


def get_translator() -> Translator:
    """ç¿»è¨³ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å–å¾—ï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ï¼‰"""
    global _translator_instance
    if _translator_instance is None:
        _translator_instance = Translator()
    return _translator_instance


def translate_text(text: str) -> str:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’ç¿»è¨³ã™ã‚‹ä¾¿åˆ©é–¢æ•°

    Args:
        text: ç¿»è¨³å¯¾è±¡ã®æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆ

    Returns:
        ç¿»è¨³ã•ã‚ŒãŸè‹±èªãƒ†ã‚­ã‚¹ãƒˆ
    """
    translator = get_translator()
    return translator.translate_text(text)
