import tempfile
import subprocess
import os

from faster_whisper import WhisperModel
from faster_whisper.vad import VadOptions
from fastapi import UploadFile, HTTPException

from config import settings
from utils.logger import logger

whisper_model = WhisperModel(
    settings.WHISPER_MODEL_SIZE,
    device=settings.WHISPER_DEVICE,
    compute_type=settings.WHISPER_COMPUTE_TYPE,
    cpu_threads=settings.WHISPER_CPU_THREADS,
    num_workers=settings.WHISPER_NUM_WORKERS,
)


async def transcribe_audio(file: UploadFile) -> str:
    tmp_path = None
    converted_path = None
    try:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
        suffix = os.path.splitext(file.filename)[1] or ".webm"
        with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
            tmp.write(await file.read())
            tmp_path = tmp.name

        # ffmpegã§16kHz/ãƒ¢ãƒãƒ©ãƒ«ã«å¤‰æ›ï¼ˆWhisperæœ€é©åŒ–ï¼‰
        converted_path = tmp_path.rsplit(".", 1)[0] + "_16k.wav"
        subprocess.run(
            [
                "ffmpeg",
                "-y",
                "-i",
                tmp_path,
                "-ar",
                "16000",
                "-ac",
                "1",
                "-af",
                "loudnorm",  # éŸ³é‡æ­£è¦åŒ–
                converted_path,
            ],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL,
        )

        vad_options = VadOptions(
            min_silence_duration_ms=settings.WHISPER_VAD_MIN_SILENCE_MS,
            speech_pad_ms=settings.WHISPER_VAD_SPEECH_PAD_MS,
        )

        # Whisperã§æ–‡å­—èµ·ã“ã—
        segments, info = whisper_model.transcribe(
            converted_path,
            language="ja",
            beam_size=settings.WHISPER_BEAM_SIZE,
            best_of=settings.WHISPER_BEST_OF,
            temperature=settings.WHISPER_TEMPERATURE,
            vad_filter=settings.WHISPER_VAD_ENABLED,
            vad_parameters=vad_options,
        )

        logger.info(f"âœ…ï¸infoå‡ºåŠ›: {info}")

        texts = []
        has_speech = False

        for segment in segments:
            texts.append(segment.text)
            has_speech = True

        if not has_speech:
            raise ValueError("éŸ³å£°ãŒèªè­˜ã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼ˆç„¡éŸ³ã¾ãŸã¯ãƒã‚¤ã‚ºã®å¯èƒ½æ€§ï¼‰")

        text = "".join(texts).strip()

        if not text:
            raise ValueError("éŸ³å£°è§£æçµæœãŒç©ºã§ã—ãŸ")

        logger.info(f"ğŸ—£ Whisperå‡ºåŠ›: {text}")

        return text

    except subprocess.CalledProcessError:
        raise HTTPException(status_code=500, detail="éŸ³å£°å¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")

    finally:
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤
        if tmp_path and os.path.exists(tmp_path):
            os.remove(tmp_path)
        if converted_path and os.path.exists(converted_path):
            os.remove(converted_path)
